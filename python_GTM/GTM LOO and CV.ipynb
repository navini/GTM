{
 "metadata": {
  "name": "",
  "signature": "sha256:254a2a7ffc6bf0c24a4d1d1fa66ffd670711ec92cb29e184ad887b8ede01c835"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from scipy import linalg\n",
      "from scipy import sparse\n",
      "from matplotlib import pyplot as plt\n",
      "import random\n",
      "import sys\n",
      "import math\n",
      "import neuralnetworks as nn\n",
      "import random\n",
      "from __future__ import division\n",
      "\n",
      "def normalize(signal):\n",
      "    means = np.mean(signal, axis=1).reshape((signal.shape[0],1))\n",
      "    std = np.std(signal, axis=1).reshape((signal.shape[0],1))\n",
      "    signal = np.divide(np.subtract(signal,means),std)\n",
      "    return signal\n",
      "    \n",
      "\n",
      "def gtm_rctg(samp_size):\n",
      "    xDim = samp_size\n",
      "    yDim = samp_size\n",
      "    # Produce a grid with the right number of rows and columns\n",
      "    X, Y = np.meshgrid(np.linspace(0,(xDim-1),xDim), np.linspace(0,(yDim-1),yDim))\n",
      "    # Change grid representation \n",
      "    sample = np.zeros((xDim**2,2))\n",
      "    sample[:,0:1]=np.reshape(X,(xDim**2,1),1)\n",
      "    sample[:,1:2]=np.reshape(Y,(yDim**2,1),1)\n",
      "    # Shift grid to correct position and scale it\n",
      "    maxXY= np.max(sample,0);\n",
      "    sample[:,0:1] = 2*(sample[:,0:1] - maxXY[0]/2)/maxXY[0]\n",
      "    sample[:,1:2] = -2*(sample[:,1:2] - maxXY[1]/2)/maxXY[1]\n",
      "    return sample\n",
      "\n",
      "def dist(x,c):\n",
      "#Calculate squared euclidean distance between x and c\n",
      "    ndata = x.shape[0]\n",
      "    dimx = x.shape[1]\n",
      "    ncentres = c.shape[0]\n",
      "    dimc = c.shape[1]\n",
      "    x2 = np.reshape(sum(np.square(x).T),(1,ndata))\n",
      "    c2 = np.reshape(sum(np.square(c).T),(1,ncentres))\n",
      "    n2 = (np.dot(np.ones((ncentres, 1)) , x2)).T +np.dot(np.ones((ndata, 1)),c2) -  2*(np.dot(x,c.T))\n",
      "    # Rounding errors occasionally cause negative entries in n2\n",
      "    n2 = np.where(n2>=0,n2,0)\n",
      "    return n2\n",
      "\n",
      "def rbfsetfw(rbf_c,rbf_w,scale):   \n",
      "# Set the function widths of the RBF network\n",
      "    cdist = dist(rbf_c,rbf_c)\n",
      "    if scale > 0.0:\n",
      "    # Set variance of basis to be scale times average distance to nearest neighbour\n",
      "        cdist = cdist + sys.float_info.max*np.eye(rbf_c.shape[0])\n",
      "        widths = scale*np.mean((cdist).min(axis=0))\n",
      "    else:\n",
      "        widths = np.max(cdist)\n",
      "    wi = widths * np.ones(rbf_w.shape)\n",
      "    return wi\n",
      "\n",
      "def eigdec(x, N):\n",
      "    temp_evals, temp_evec = np.linalg.eig(x)\n",
      "    #temp_evals = np.sort(temp_evals)\n",
      "    evals = np.sort(-temp_evals)\n",
      "    perm = np.argsort(-temp_evals)\n",
      "    evals = -evals[0:N]\n",
      "    evec = np.zeros((temp_evec.shape[0],N), dtype=complex)\n",
      "    if (evals[0:N] == temp_evals[0:N]).all():\n",
      "        evec = temp_evec[:,0:N]\n",
      "    else:\n",
      "        for i in range(N):\n",
      "            evec[:,i] = temp_evec[:,perm[i]] \n",
      "    return evals, evec   \n",
      "\n",
      "def rbffwd(c, x, wi, w2, b2):\n",
      "    nx = x.shape[0]\n",
      "    ndim = x.shape[1]\n",
      "    n2 = dist(x, c)\n",
      "    # Calculate width factors: net.wi contains squared widths\n",
      "    wi2 = np.ones((nx, 1)) * (2 * wi)\n",
      "    # Now compute the activations\n",
      "    z = np.exp(-(n2/wi2))\n",
      "    a = np.dot(z,w2) + np.dot(np.ones((nx, 1)),b2)\n",
      "    return a, z, n2\n",
      "\n",
      "def gmmactive(nin, covars, gmm_c, ncentres, data):\n",
      "    a = np.zeros((data.shape[0], ncentres))\n",
      "    # Calculate squared norm matrix, of dimension (ndata, ncentres)\n",
      "    n2 = dist(data, gmm_c)\n",
      "    # Calculate width factors\n",
      "    wi2 = np.dot(np.ones((data.shape[0], 1)), (2 * covars))\n",
      "    #normal = (math.pi* wi2)**(nin/2)\n",
      "    # Now compute the activations\n",
      "    #a = np.exp(-(n2/wi2))/ normal\n",
      "    a = np.exp(-(n2/wi2))\n",
      "    return a\n",
      "    \n",
      "\n",
      "def gtmpost(nin, covars, gmm_c, ncentres, priors, rbf_c, X, wi, w2, b2, data):\n",
      "    gmm_centres = rbffwd(rbf_c, X, wi, w2, b2)\n",
      "    a = gmmactive(nin, covars, gmm_c, ncentres, data)\n",
      "    post = (np.dot(np.ones((data.shape[0], 1)),priors))*a\n",
      "    s = np.reshape(post.sum(axis=1).T,(data.shape[0],1))\n",
      "    # Set any zeros to one before dividing\n",
      "    s = np.where(s>0,s,1)\n",
      "    post = post/np.dot(s,np.ones((1, ncentres)))\n",
      "    return post, a\n",
      "\n",
      "#*******************************************************************************************************************************************88\n",
      "    \t\n",
      "    \n",
      "data=np.loadtxt('plots/S24/Data/S24LDP3-smoothed.txt')\n",
      "data_features1 = data[:,1:211]\n",
      "data_classes1 = data[:,0:1]\n",
      "###########Print Confusion Matrix\n",
      "\n",
      "print data_features1.shape\n",
      "BSR = np.zeros((10,1))\n",
      "\n",
      "for k in range(10):\n",
      "    for j in range(10):\n",
      "        TP=0\n",
      "        TN=0\n",
      "        FP=0\n",
      "        FN=0\n",
      "\n",
      "        for i in range(data_features1.shape[0]):\n",
      "            print i\n",
      "            test_data = data_features1[i:i+1,:]\n",
      "            test_classes = data_classes1[i:i+1,:]\n",
      "            data_featurestrain = np.delete(data_features1, (i), axis=0 )\n",
      "            train_classes = np.delete(data_classes1, (i), axis=0 )\n",
      "\n",
      "\n",
      "            #data_dim = data_features.shape[1]  # Data dimension\n",
      "            data_dim = 210\n",
      "            data_samples = data_featurestrain.shape[0]\n",
      "\n",
      "            data_features = normalize(data_featurestrain)\n",
      "            test_data = normalize(test_data)\n",
      "            data_classes = train_classes\n",
      "\n",
      "\n",
      "            # Create the latent space\n",
      "\n",
      "            latent_dim_points = 15  # Number of latent points in each dimension\n",
      "            nlatent = latent_dim_points**2  # Number of latent points\n",
      "            latent_dim = 2  # Dimension of the latent space\n",
      "\n",
      "\n",
      "            #plt.plot(data_features[0,:],)\n",
      "            #plt.show()\n",
      "\n",
      "            ########## Create the GTM \n",
      "\n",
      "            gtm_nin = data_dim     # Number of input units to the GTM\n",
      "            gtm_dimLatent = latent_dim   #Latent dimension of the GTM\n",
      "            gtm_X = []      # Sample latent points in the GTM\n",
      "\n",
      "            ########### Create the RBF space\n",
      "\n",
      "            rbf_dim_points = 4\n",
      "            rbf_width_factor = 1\n",
      "            num_rbf_centres = rbf_dim_points**2\n",
      "            rbf_nhidden = num_rbf_centres  # Number of hidden units\n",
      "            rbf_nin = latent_dim     # Number of input units\n",
      "            rbf_nout = data_dim    # Number of output units\n",
      "            rbf_nwts = (rbf_nin+1)*rbf_nhidden + (rbf_nhidden+1)*rbf_nout   # Number of total weights and biases\n",
      "            rbf_actfn = 'gaussian'  # For radially symmetric gaussian functions as the activation function, the implementation is based on gaussian\n",
      "            rbf_outfn = 'linear'    # Defines the output error function, linear for linear outputs and SoS error\n",
      "            # Separate the weights into its components, initialized to random normal values\n",
      "            w = np.random.randn(1,rbf_nwts)\n",
      "            mark1 = rbf_nin*rbf_nhidden\n",
      "            mark2 = mark1 + rbf_nhidden\n",
      "            mark3 = mark2 + rbf_nhidden*rbf_nout\n",
      "            mark4 = mark3 + rbf_nout\n",
      "            rbf_centres = np.reshape(w[:,0:mark1],(rbf_nhidden,rbf_nin))   # RBF centres   \n",
      "            rbf_wi = np.reshape(w[:,mark1:mark2],(1,rbf_nhidden))   # Squared widths needed for 'gaussian' type activation function\n",
      "            rbf_w2 = np.reshape(w[:,mark2:mark3],(rbf_nhidden,rbf_nout))  # 2nd layer weight matrix \n",
      "            rbf_b2 = np.reshape(w[:,mark3:mark4],(1,rbf_nout))   # 2nd layer bias vector\n",
      "            #Make widths equal to one\n",
      "            rbf_wi = np.ones((1,rbf_nhidden))\n",
      "\n",
      "            ########## Create the Gaussian Mixture model\n",
      "\n",
      "            gmm_nin = data_dim\n",
      "            gmm_ncentres = nlatent\n",
      "            gmm_covartype = 'spherical'  # Allows single variance parameter for each component(stored as a vector)\n",
      "            gmm_priors = np.ones((1,gmm_ncentres))/gmm_ncentres    #Priors are the mixing coefficients. Initialized to equal values summing to one, and the covariance are all the identity matrices\n",
      "            gmm_centres = np.random.randn(gmm_ncentres,gmm_nin)   # Initialized from tandom normal distribution\n",
      "            gmm_covars = np.ones((1,gmm_ncentres))\n",
      "            gmm_nwts = gmm_ncentres + gmm_ncentres*gmm_nin + gmm_ncentres    # Total number of weights and biases\n",
      "\n",
      "\n",
      "            ######## Initialize the weights and latent samples in the GTM. Generates a sample of latent data points and sets the centres and widths of the RBF network\n",
      "\n",
      "            gtm_X = gtm_rctg(latent_dim_points)\n",
      "            rbf_centres = gtm_rctg(rbf_dim_points)\n",
      "            rbf_wi = rbfsetfw(rbf_centres, rbf_wi, rbf_width_factor)\n",
      "            # Calculate the principal components\n",
      "\n",
      "            PCcoeff, PCvec = eigdec(np.cov(data_features.T), data_features.shape[1])\n",
      "            PCcoeff = np.reshape(PCcoeff,(1,PCcoeff.shape[0]))\n",
      "\n",
      "            A = np.dot(PCvec[:, 0:gtm_dimLatent],np.diag(np.asarray(np.sqrt(PCcoeff[:,0:gtm_dimLatent])).reshape(-1)))\n",
      "\n",
      "            # Forward prpagate through the RBF network\n",
      "            a , Phi, dist1 = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "            # Normalise X to ensure 1:1 mapping of variances and calculate weights as solution of Phi*W = normX*A'\n",
      "            normX = np.dot((gtm_X - np.dot(np.ones(gtm_X.shape),np.diag(np.mean(gtm_X,0)))),np.diag(1/np.std(gtm_X,0)))\n",
      "            g = np.dot(normX,A.T)\n",
      "            x_sol, residues, rank, singV = linalg.lstsq(Phi,g)            \n",
      "            rbf_w2 = np.asarray(x_sol)\n",
      "            # Bias is mean of target data\n",
      "            rbf_b2 = np.reshape(np.mean(data_features,axis=0),(data_dim,1)).T\n",
      "            # Must also set initial value of variance. Find average distance between nearest centres. Ensure that distance of centre to itself is excluded by setting diagonal entries to realmax\n",
      "            gmm_centres, not_used1, not_used2 = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "            #print  'gmm_centres',gmm_centres\n",
      "            d = dist(gmm_centres, gmm_centres) + np.matrix(np.identity(gmm_ncentres))*sys.float_info.max\n",
      "\n",
      "            sigma = np.mean(d.min(axis=0))/2\n",
      "            # Now set covariance to minimum of this and next largest eigenvalue\n",
      "            if gtm_dimLatent < data.shape[1]:\n",
      "              sigma = min(sigma, PCcoeff[:,gtm_dimLatent:gtm_dimLatent+1]);\n",
      "\n",
      "            gmm_covars = sigma*np.ones((1, gmm_ncentres))\n",
      "\n",
      "\n",
      "\n",
      "            ############ Training the model with EM algorithm #########################################\n",
      "\n",
      "            niters = 30\n",
      "            ND = data_dim * data_samples \n",
      "            gmm_centres, Phi, l = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "            Phi = np.hstack((Phi, np.ones((gtm_X.shape[0], 1))))\n",
      "            PhiT = Phi.T\n",
      "            K, Mplus1 = Phi.shape\n",
      "\n",
      "\n",
      "            for n in range(niters):\n",
      "\n",
      "                # Calculate responsibilities\n",
      "                R, act = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, data_features)\n",
      "                # Calculate matrix be inverted (Phi'*G*Phi + alpha*I in the papers).\n",
      "                # Sparse representation of G normally executes faster and saves memory\n",
      "                A = np.dot(PhiT,np.dot(sparse.spdiags(np.sum(R,axis=0).T, 0, K, K).todense(),Phi))\n",
      "                W = np.linalg.solve(A,np.dot(PhiT,np.dot(R.T,data_features)))\n",
      "                rbf_w2 = W[0:rbf_nhidden, :]\n",
      "                #print rbf_w2.shape\n",
      "                rbf_b2 = W[rbf_nhidden:rbf_nhidden+1, :]\n",
      "                #print rbf_b2.shape\n",
      "                d = dist(data_features, np.dot(Phi,W))\n",
      "\n",
      "                # Calculate new value for beta\n",
      "                gmm_covars = np.dot(np.ones((1, gmm_ncentres)),(sum(sum(d*R))/ND))\n",
      "                #print gmm_covars.shape\n",
      "\n",
      "\n",
      "\n",
      "            forMM, notused = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, data_features)\n",
      "\n",
      "            means = np.dot(forMM, gtm_X)\n",
      "\n",
      "\n",
      "            targetcount = 0\n",
      "            nontargetcount = 0\n",
      "            if(test_classes==0):\n",
      "                targetPoints = np.zeros((20,3))\n",
      "                nontargetPoints = np.zeros((59,3))\n",
      "            else:\n",
      "                targetPoints = np.zeros((19,3))\n",
      "                nontargetPoints = np.zeros((60,3))\n",
      "            for i in range(data_classes.shape[0]):\n",
      "                if data_classes[i,0]==0:\n",
      "                    #lo=axes1.plot(means[i,0], means[i,1], 'r.')\n",
      "                    nontargetPoints[nontargetcount,0]=means[i,0]\n",
      "                    nontargetPoints[nontargetcount,1]=means[i,1]\n",
      "                    nontargetPoints[nontargetcount,2]=0\n",
      "                    nontargetcount=nontargetcount+1;\n",
      "                if data_classes[i,0]==1:\n",
      "                    #lx=axes1.plot(means[i,0], means[i,1], 'bx')\n",
      "                    targetPoints[targetcount,0]=means[i,0]\n",
      "                    targetPoints[targetcount,1]=means[i,1]\n",
      "                    targetPoints[targetcount,2]=1\n",
      "                    targetcount=targetcount+1;\n",
      "\n",
      "            X= np.vstack((nontargetPoints,targetPoints))\n",
      "            #axes1.set_title('Latent space')\n",
      "            #fig.show()\n",
      "            #plt.show()\n",
      "\n",
      "            forMM, notused = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, test_data)\n",
      "            means = np.dot(forMM, gtm_X)\n",
      "\n",
      "\n",
      "            nnet = nn.NeuralNetClassifier(2,j+1,2) # 2 inputs, 8 hiddens, 3 outputs\n",
      "            nnet.train(X[:,0:2],X[:,2:3],weightPrecision=1.e-8,errorPrecision=1.e-8,nIterations=400)\n",
      "            print \"SCG stopped after\",nnet.getNumberOfIterations(),\"iterations:\",nnet.reason\n",
      "            (classes,Y,Z) = nnet.use(X[:,0:2], allOutputs=True)\n",
      "\n",
      "\n",
      "            marker = ['r.','bx']\n",
      "            predTest,probs,Z = nnet.use(means,allOutputs=True) \n",
      "            print predTest\n",
      "\n",
      "\n",
      "            if(predTest[0,:]==test_classes[0,:]):\n",
      "                if(predTest[0,:]==0):\n",
      "                    TN=TN+1\n",
      "                else:\n",
      "                    TP=TP+1\n",
      "            else:\n",
      "                if(predTest[0,:]==0):\n",
      "                    FN=FN+1\n",
      "                else:\n",
      "                    FP=FP+1\n",
      "\n",
      "\n",
      "        print '\\t Confusion matrix'\n",
      "\n",
      "        print '\\t    predicted labels'\n",
      "        print '\\t \\t 0 \\t 1'\n",
      "\n",
      "        print 'true lables 0   ',TN,'\\t ',FP\n",
      "        print '\\t    1   ',FN,'\\t ',TP\n",
      "\n",
      "        BSR[j,0] = BSR[j,0]+((TP/(TP+FN) + TN/(TN+FP))/2)\n",
      "        print BSR\n",
      "        \n",
      "BSR = BSR*10\n",
      "print BSR\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:281: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "-c:282: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "-c:275: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "-c:276: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "neuralnetworks.py:295: RuntimeWarning: overflow encountered in exp\n",
        "  expY = np.exp(Y)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(80L, 210L)\n",
        "0\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "1\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 80 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "2\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 178 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "3\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 57 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "4\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 109 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "5\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 90 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "6\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 306 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "7\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 54 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "8\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 0.]]\n",
        "9\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 260 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "10\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 105 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "11\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 94 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "12\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 290 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "13\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 60 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "14\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 117 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "15\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 98 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "16\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 155 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "17\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 128 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "18\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "19\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 112 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "20\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 65 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "21\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "22\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 157 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "23\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 60 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "24\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 137 iterations: limit on f Precision\n",
        "[[ 1.]]\n",
        "25\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 112 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "26\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "27\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 76 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "28\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 95 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "29\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 59 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "30\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 0.]]\n",
        "31\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 133 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "32\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "33\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 341 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "34\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 307 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "35\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 91 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "36\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 330 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "37\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "38\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 77 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "39\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 77 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "40\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 106 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "41\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 180 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "42\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 137 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "43\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "44\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "45\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 82 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "46\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 49 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "47\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 122 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "48\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 123 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "49\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 141 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "50\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 183 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "51\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 69 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "52\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 161 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "53\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 189 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "54\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 67 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "55\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 88 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "56\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 130 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "57\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "58\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 321 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "59\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 212 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "60\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "61\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 219 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "62\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 49 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "63\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 126 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "64\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "65\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 112 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "66\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 60 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "67\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 122 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "68\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 274 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "69\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "70\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 106 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "71\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 107 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "72\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 102 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "73\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 149 iterations: limit on f Precision\n",
        "[[ 0.]]\n",
        "74\n",
        "SCG stopped after"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}