{
 "metadata": {
  "name": "",
  "signature": "sha256:805edbd283269afc1eb4a98cb4b3dc885451598694e7f6de75f871b578812f2f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from scipy import linalg\n",
      "from scipy import sparse\n",
      "from matplotlib import pyplot as plt\n",
      "import random\n",
      "import sys\n",
      "import math\n",
      "from __future__ import division\n",
      "import neuralnetworks as nn\n",
      "import random\n",
      "\n",
      "def normalize(signal):\n",
      "    means = np.mean(signal, axis=1).reshape((signal.shape[0],1))\n",
      "    std = np.std(signal, axis=1).reshape((signal.shape[0],1))\n",
      "    signal = np.divide(np.subtract(signal,means),std)\n",
      "    return signal\n",
      "    \n",
      "\n",
      "def gtm_rctg(samp_size):\n",
      "    xDim = samp_size\n",
      "    yDim = samp_size\n",
      "    # Produce a grid with the right number of rows and columns\n",
      "    X, Y = np.meshgrid(np.linspace(0,(xDim-1),xDim), np.linspace(0,(yDim-1),yDim))\n",
      "    # Change grid representation \n",
      "    sample = np.zeros((xDim**2,2))\n",
      "    sample[:,0:1]=np.reshape(X,(xDim**2,1),1)\n",
      "    sample[:,1:2]=np.reshape(Y,(yDim**2,1),1)\n",
      "    # Shift grid to correct position and scale it\n",
      "    maxXY= np.max(sample,0);\n",
      "    sample[:,0:1] = 2*(sample[:,0:1] - maxXY[0]/2)/maxXY[0]\n",
      "    sample[:,1:2] = -2*(sample[:,1:2] - maxXY[1]/2)/maxXY[1]\n",
      "    return sample\n",
      "\n",
      "def dist(x,c):\n",
      "#Calculate squared euclidean distance between x and c\n",
      "    ndata = x.shape[0]\n",
      "    dimx = x.shape[1]\n",
      "    ncentres = c.shape[0]\n",
      "    dimc = c.shape[1]\n",
      "    x2 = np.reshape(sum(np.square(x).T),(1,ndata))\n",
      "    c2 = np.reshape(sum(np.square(c).T),(1,ncentres))\n",
      "    n2 = (np.dot(np.ones((ncentres, 1)) , x2)).T +np.dot(np.ones((ndata, 1)),c2) -  2*(np.dot(x,c.T))\n",
      "    # Rounding errors occasionally cause negative entries in n2\n",
      "    n2 = np.where(n2>=0,n2,0)\n",
      "    return n2\n",
      "\n",
      "def rbfsetfw(rbf_c,rbf_w,scale):   \n",
      "# Set the function widths of the RBF network\n",
      "    cdist = dist(rbf_c,rbf_c)\n",
      "    if scale > 0.0:\n",
      "    # Set variance of basis to be scale times average distance to nearest neighbour\n",
      "        cdist = cdist + sys.float_info.max*np.eye(rbf_c.shape[0])\n",
      "        widths = scale*np.mean((cdist).min(axis=0))\n",
      "    else:\n",
      "        widths = np.max(cdist)\n",
      "    wi = widths * np.ones(rbf_w.shape)\n",
      "    return wi\n",
      "\n",
      "def eigdec(x, N):\n",
      "    temp_evals, temp_evec = np.linalg.eig(x)\n",
      "    #temp_evals = np.sort(temp_evals)\n",
      "    evals = np.sort(-temp_evals)\n",
      "    perm = np.argsort(-temp_evals)\n",
      "    evals = -evals[0:N]\n",
      "    evec = np.zeros((temp_evec.shape[0],N), dtype=complex)\n",
      "    if (evals[0:N] == temp_evals[0:N]).all():\n",
      "        evec = temp_evec[:,0:N]\n",
      "    else:\n",
      "        for i in range(N):\n",
      "            evec[:,i] = temp_evec[:,perm[i]] \n",
      "    return evals, evec   \n",
      "\n",
      "def rbffwd(c, x, wi, w2, b2):\n",
      "    nx = x.shape[0]\n",
      "    ndim = x.shape[1]\n",
      "    n2 = dist(x, c)\n",
      "    # Calculate width factors: net.wi contains squared widths\n",
      "    wi2 = np.ones((nx, 1)) * (2 * wi)\n",
      "    # Now compute the activations\n",
      "    z = np.exp(-(n2/wi2))\n",
      "    a = np.dot(z,w2) + np.dot(np.ones((nx, 1)),b2)\n",
      "    return a, z, n2\n",
      "\n",
      "def gmmactive(nin, covars, gmm_c, ncentres, data):\n",
      "    a = np.zeros((data.shape[0], ncentres))\n",
      "    # Calculate squared norm matrix, of dimension (ndata, ncentres)\n",
      "    n2 = dist(data, gmm_c)\n",
      "    # Calculate width factors\n",
      "    wi2 = np.dot(np.ones((data.shape[0], 1)), (2 * covars))\n",
      "    #normal = (math.pi* wi2)**(nin/2)\n",
      "    # Now compute the activations\n",
      "    #a = np.exp(-(n2/wi2))/ normal\n",
      "    a = np.exp(-(n2/wi2))\n",
      "    return a\n",
      "    \n",
      "\n",
      "def gtmpost(nin, covars, gmm_c, ncentres, priors, rbf_c, X, wi, w2, b2, data):\n",
      "    gmm_centres = rbffwd(rbf_c, X, wi, w2, b2)\n",
      "    a = gmmactive(nin, covars, gmm_c, ncentres, data)\n",
      "    post = (np.dot(np.ones((data.shape[0], 1)),priors))*a\n",
      "    s = np.reshape(post.sum(axis=1).T,(data.shape[0],1))\n",
      "    # Set any zeros to one before dividing\n",
      "    s = np.where(s>0,s,1)\n",
      "    post = post/np.dot(s,np.ones((1, ncentres)))\n",
      "    return post, a\n",
      "\n",
      "#*******************************************************************************************************************************************88\n",
      "    \t\n",
      "    \n",
      "data=np.loadtxt('classData4smoothed.txt')\n",
      "\n",
      "\n",
      "BSR = 0\n",
      "\n",
      "for i in range(10):\n",
      "    data_features = data[:,1:211]\n",
      "    data_classes = data[:,0:1]\n",
      "\n",
      "    trainf = 0.8\n",
      "    nontarget,_ = np.where(data_classes == 0)\n",
      "    target,_ = np.where(data_classes == 1)\n",
      "    nontarget = np.random.permutation(nontarget)\n",
      "    target = np.random.permutation(target)\n",
      "\n",
      "    n = round(trainf*len(nontarget))\n",
      "    rows = nontarget[:n]\n",
      "    data_featurestrain = data_features[rows,:]\n",
      "    data_classestrain = data_classes[rows,:]\n",
      "    rows = nontarget[n:]\n",
      "    data_featurestest =  data_features[rows,:]\n",
      "    data_classestest =  data_classes[rows,:]\n",
      "    n = round(trainf*len(target))\n",
      "    rows = target[:n]\n",
      "    data_featurestrain = np.vstack((data_featurestrain, data_features[rows,:]))\n",
      "    data_classestrain = np.vstack((data_classestrain, data_classes[rows,:]))\n",
      "    rows = target[n:]\n",
      "    data_featurestest = np.vstack((data_featurestest, data_features[rows,:]))\n",
      "    data_classestest = np.vstack((data_classestest, data_classes[rows,:]))\n",
      "\n",
      "    print data_classestest\n",
      "\n",
      "    #data_dim = data_features.shape[1]  # Data dimension\n",
      "    data_dim = 210\n",
      "    data_samples = data_featurestrain.shape[0]\n",
      "\n",
      "    data_features = normalize(data_featurestrain)\n",
      "    test_data = normalize(data_featurestest)\n",
      "    data_classes = data_classestrain\n",
      "    test_classes = data_classestest\n",
      "\n",
      "    # Create the latent space\n",
      "\n",
      "    latent_dim_points = 15  # Number of latent points in each dimension\n",
      "    nlatent = latent_dim_points**2  # Number of latent points\n",
      "    latent_dim = 2  # Dimension of the latent space\n",
      "\n",
      "\n",
      "    #plt.plot(data_features[0,:],)\n",
      "    #plt.show()\n",
      "\n",
      "    ########## Create the GTM \n",
      "\n",
      "    gtm_nin = data_dim     # Number of input units to the GTM\n",
      "    gtm_dimLatent = latent_dim   #Latent dimension of the GTM\n",
      "    gtm_X = []      # Sample latent points in the GTM\n",
      "\n",
      "    ########### Create the RBF space\n",
      "\n",
      "    rbf_dim_points = 4\n",
      "    rbf_width_factor = 1\n",
      "    num_rbf_centres = rbf_dim_points**2\n",
      "    rbf_nhidden = num_rbf_centres  # Number of hidden units\n",
      "    rbf_nin = latent_dim     # Number of input units\n",
      "    rbf_nout = data_dim    # Number of output units\n",
      "    rbf_nwts = (rbf_nin+1)*rbf_nhidden + (rbf_nhidden+1)*rbf_nout   # Number of total weights and biases\n",
      "    rbf_actfn = 'gaussian'  # For radially symmetric gaussian functions as the activation function, the implementation is based on gaussian\n",
      "    rbf_outfn = 'linear'    # Defines the output error function, linear for linear outputs and SoS error\n",
      "    # Separate the weights into its components, initialized to random normal values\n",
      "    w = np.random.randn(1,rbf_nwts)\n",
      "    mark1 = rbf_nin*rbf_nhidden\n",
      "    mark2 = mark1 + rbf_nhidden\n",
      "    mark3 = mark2 + rbf_nhidden*rbf_nout\n",
      "    mark4 = mark3 + rbf_nout\n",
      "    rbf_centres = np.reshape(w[:,0:mark1],(rbf_nhidden,rbf_nin))   # RBF centres   \n",
      "    rbf_wi = np.reshape(w[:,mark1:mark2],(1,rbf_nhidden))   # Squared widths needed for 'gaussian' type activation function\n",
      "    rbf_w2 = np.reshape(w[:,mark2:mark3],(rbf_nhidden,rbf_nout))  # 2nd layer weight matrix \n",
      "    rbf_b2 = np.reshape(w[:,mark3:mark4],(1,rbf_nout))   # 2nd layer bias vector\n",
      "    #Make widths equal to one\n",
      "    rbf_wi = np.ones((1,rbf_nhidden))\n",
      "\n",
      "    ########## Create the Gaussian Mixture model\n",
      "\n",
      "    gmm_nin = data_dim\n",
      "    gmm_ncentres = nlatent\n",
      "    gmm_covartype = 'spherical'  # Allows single variance parameter for each component(stored as a vector)\n",
      "    gmm_priors = np.ones((1,gmm_ncentres))/gmm_ncentres    #Priors are the mixing coefficients. Initialized to equal values summing to one, and the covariance are all the identity matrices\n",
      "    gmm_centres = np.random.randn(gmm_ncentres,gmm_nin)   # Initialized from tandom normal distribution\n",
      "    gmm_covars = np.ones((1,gmm_ncentres))\n",
      "    gmm_nwts = gmm_ncentres + gmm_ncentres*gmm_nin + gmm_ncentres    # Total number of weights and biases\n",
      "\n",
      "\n",
      "    ######## Initialize the weights and latent samples in the GTM. Generates a sample of latent data points and sets the centres and widths of the RBF network\n",
      "\n",
      "    gtm_X = gtm_rctg(latent_dim_points)\n",
      "    rbf_centres = gtm_rctg(rbf_dim_points)\n",
      "    rbf_wi = rbfsetfw(rbf_centres, rbf_wi, rbf_width_factor)\n",
      "    # Calculate the principal components\n",
      "\n",
      "    PCcoeff, PCvec = eigdec(np.cov(data_features.T), data_features.shape[1])\n",
      "    PCcoeff = np.reshape(PCcoeff,(1,PCcoeff.shape[0]))\n",
      "\n",
      "    A = np.dot(PCvec[:, 0:gtm_dimLatent],np.diag(np.asarray(np.sqrt(PCcoeff[:,0:gtm_dimLatent])).reshape(-1)))\n",
      "\n",
      "    # Forward prpagate through the RBF network\n",
      "    a , Phi, dist1 = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "    # Normalise X to ensure 1:1 mapping of variances and calculate weights as solution of Phi*W = normX*A'\n",
      "    normX = np.dot((gtm_X - np.dot(np.ones(gtm_X.shape),np.diag(np.mean(gtm_X,0)))),np.diag(1/np.std(gtm_X,0)))\n",
      "    g = np.dot(normX,A.T)\n",
      "    x_sol, residues, rank, singV = linalg.lstsq(Phi,g)            \n",
      "    rbf_w2 = np.asarray(x_sol)\n",
      "    # Bias is mean of target data\n",
      "    rbf_b2 = np.reshape(np.mean(data_features,axis=0),(data_dim,1)).T\n",
      "    # Must also set initial value of variance. Find average distance between nearest centres. Ensure that distance of centre to itself is excluded by setting diagonal entries to realmax\n",
      "    gmm_centres, not_used1, not_used2 = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "    #print  'gmm_centres',gmm_centres\n",
      "    d = dist(gmm_centres, gmm_centres) + np.matrix(np.identity(gmm_ncentres))*sys.float_info.max\n",
      "\n",
      "    sigma = np.mean(d.min(axis=0))/2\n",
      "    # Now set covariance to minimum of this and next largest eigenvalue\n",
      "    if gtm_dimLatent < data.shape[1]:\n",
      "      sigma = min(sigma, PCcoeff[:,gtm_dimLatent:gtm_dimLatent+1]);\n",
      "\n",
      "    gmm_covars = sigma*np.ones((1, gmm_ncentres))\n",
      "\n",
      "\n",
      "\n",
      "    ############ Training the model with EM algorithm #########################################\n",
      "\n",
      "    niters = 30\n",
      "    ND = data_dim * data_samples \n",
      "    gmm_centres, Phi, l = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "    Phi = np.hstack((Phi, np.ones((gtm_X.shape[0], 1))))\n",
      "    PhiT = Phi.T\n",
      "    K, Mplus1 = Phi.shape\n",
      "\n",
      "    '''\n",
      "    print 'gmm_covars',gmm_covars,'\\n'\n",
      "    print 'gmm_centres',gmm_centres,'\\n'\n",
      "    print 'gmm_priors',gmm_priors,'\\n'\n",
      "    print 'rbf_centres',rbf_centres,'\\n'\n",
      "    print 'gtm_X',gtm_X,'\\n'\n",
      "    print 'rbf_wi',rbf_wi,'\\n'\n",
      "    print 'rbf_w2',rbf_w2,'\\n'\n",
      "    print 'rbf_b2',rbf_b2,'\\n'\n",
      "    print 'data_features',data_features,'\\n'\n",
      "    '''\n",
      "\n",
      "    for n in range(niters):\n",
      "\n",
      "        # Calculate responsibilities\n",
      "        R, act = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, data_features)\n",
      "        # Calculate matrix be inverted (Phi'*G*Phi + alpha*I in the papers).\n",
      "        # Sparse representation of G normally executes faster and saves memory\n",
      "        A = np.dot(PhiT,np.dot(sparse.spdiags(np.sum(R,axis=0).T, 0, K, K).todense(),Phi))\n",
      "        W = np.linalg.solve(A,np.dot(PhiT,np.dot(R.T,data_features)))\n",
      "        rbf_w2 = W[0:rbf_nhidden, :]\n",
      "        #print rbf_w2.shape\n",
      "        rbf_b2 = W[rbf_nhidden:rbf_nhidden+1, :]\n",
      "        #print rbf_b2.shape\n",
      "        d = dist(data_features, np.dot(Phi,W))\n",
      "\n",
      "        # Calculate new value for beta\n",
      "        gmm_covars = np.dot(np.ones((1, gmm_ncentres)),(sum(sum(d*R))/ND))\n",
      "        #print gmm_covars.shape\n",
      "\n",
      "\n",
      "\n",
      "    forMM, notused = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, data_features)\n",
      "\n",
      "    means = np.dot(forMM, gtm_X)\n",
      "\n",
      "    # Mode is maximum responsibility\n",
      "    max_index = np.argmax(forMM, axis=1)\n",
      "    modes = gtm_X[max_index, :]\n",
      "    classes0 = np.where(data_classes==0)[0]\n",
      "    #print classes0;\n",
      "    #fig = plt.figure(figsize=(9,9))\n",
      "    #axes1 = fig.add_axes([0.1, 0.1, 0.8,0.8]) # main axes\n",
      "    '''\n",
      "    for i in classes0:\n",
      "        #print means[i,0],\" , \", means[i,1]\n",
      "        #axes2 = fig.add_axes([(means[i,0]-(-0.008))/0.012*0.8+0.1-0.01, (means[i,1]-(-0.004))/0.012*0.8+0.1-0.01, 0.05,0.05])\n",
      "        #axes2.set_alpha(0.0)\n",
      "        lo=axes1.plot(means[i,0], means[i,1], 'r.')\n",
      "        #axes2.plot(data_features[i,:],'r')\n",
      "        #axes2.axis('off')\n",
      "        #plt.plot(means[i,0], means[i,1], 'ro')\n",
      "    hold on\n",
      "    classes1 = np.where(data_classes==1)[0]\n",
      "    for i in classes1:\n",
      "        #axes2 = fig.add_axes([(means[i,0]-(-0.008))/0.012*0.8+0.1-0.01, (means[i,1]-(-0.004))/0.012*0.8+0.1-0.01, 0.05,0.05])\n",
      "        #axes2.set_alpha(0.0)\n",
      "        lx=axes1.plot(means[i,0], means[i,1],'bx')\n",
      "        #axes2.plot(data_features[i,:],'b')\n",
      "        #axes2.axis('off')\n",
      "    #axes1.set_xlabel('x')\n",
      "    #axes1.set_ylabel('y')'''\n",
      "\n",
      "\n",
      "    targetcount = 0\n",
      "    nontargetcount = 0\n",
      "    targetPoints = np.zeros((20,3))\n",
      "    nontargetPoints = np.zeros((60,3))\n",
      "    for i in range(data_classes.shape[0]):\n",
      "        if data_classes[i,0]==0:\n",
      "            #lo=axes1.plot(means[i,0], means[i,1], 'r.')\n",
      "            #axes1.plot(modes[i,0], modes[i,1], 'rx')\n",
      "            nontargetPoints[nontargetcount,0]=means[i,0]\n",
      "            nontargetPoints[nontargetcount,1]=means[i,1]\n",
      "            nontargetPoints[nontargetcount,2]=0\n",
      "            nontargetcount=nontargetcount+1;\n",
      "        if data_classes[i,0]==1:\n",
      "            #lx=axes1.plot(means[i,0], means[i,1], 'b.')\n",
      "            #axes1.plot(modes[i,0], modes[i,1], 'bx')\n",
      "            targetPoints[targetcount,0]=means[i,0]\n",
      "            targetPoints[targetcount,1]=means[i,1]\n",
      "            targetPoints[targetcount,2]=1\n",
      "            targetcount=targetcount+1;\n",
      "        #axes1.plot([means[i,0],modes[i,0]],[means[i,1],modes[i,1]],'g-')\n",
      "\n",
      "    X= np.vstack((nontargetPoints,targetPoints))\n",
      "    #axes1.set_title('Latent space')\n",
      "    #fig.show()\n",
      "    #plt.show()\n",
      "\n",
      "    forMM, notused = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, test_data)\n",
      "    means = np.dot(forMM, gtm_X)\n",
      "\n",
      "\n",
      "    nnet = nn.NeuralNetClassifier(2,3,2) # 2 inputs, 8 hiddens, 3 outputs\n",
      "    nnet.train(X[:,0:2],X[:,2:3],weightPrecision=1.e-8,errorPrecision=1.e-8,nIterations=400)\n",
      "    print \"SCG stopped after\",nnet.getNumberOfIterations(),\"iterations:\",nnet.reason\n",
      "    #(classes,Y,Z) = nnet.use(X[:,0:2], allOutputs=True)\n",
      "    #fig2=plt.figure()\n",
      "    #nnet.draw()\n",
      "    #fig2.show()\n",
      "\n",
      "    marker = ['r.','bx']\n",
      "    xs = np.linspace(-1,1,40)\n",
      "    x,y = np.meshgrid(xs,xs)\n",
      "    Xtest = np.vstack((x.flat,y.flat)).T\n",
      "    Ytest = nnet.use(Xtest)\n",
      "    predTest,probs,Z = nnet.use(means,allOutputs=True) \n",
      "    print predTest\n",
      "    #fig3 = plt.figure(figsize=(9,9))\n",
      "    #plt.subplot(1,1,1)\n",
      "    #for c in range(0,2):\n",
      "        #mask = (predTest == c).flatten()\n",
      "        #plt.plot(means[mask,0],means[mask,1],marker[c],markersize=5,alpha=0.9,)\n",
      "    #fig3.show()\n",
      "\n",
      "    ###########Print Confusion Matrix\n",
      "    TP=0\n",
      "    TN=0\n",
      "    FP=0\n",
      "    FN=0\n",
      "\n",
      "    for i in range(predTest.size):\n",
      "        if(predTest[i,:]==test_classes[i,:]):\n",
      "            if(predTest[i,:]==0):\n",
      "                TN=TN+1\n",
      "            else:\n",
      "                TP=TP+1\n",
      "        else:\n",
      "            if(predTest[i,:]==0):\n",
      "                FN=FN+1\n",
      "            else:\n",
      "                FP=FP+1\n",
      "\n",
      "    print '\\t Confusion matrix'\n",
      "\n",
      "    print '\\t    predicted labels'\n",
      "    print '\\t \\t 0 \\t 1'\n",
      "\n",
      "    print 'true lables 0   ',TN,'\\t ',FP\n",
      "    print '\\t    1   ',FN,'\\t ',TP\n",
      "\n",
      "    BSR = BSR+(TP/(TP+FN) + TN/(TN+FP))/2\n",
      "    \n",
      "print BSR*10\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:319: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "-c:320: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "-c:326: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "-c:327: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "neuralnetworks.py:295: RuntimeWarning: overflow encountered in exp\n",
        "  expY = np.exp(Y)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 0.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    10 \t  2\n",
        "\t    1    1 \t  3\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    11 \t  1\n",
        "\t    1    3 \t  1\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 192 iterations: limit on f Precision\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    12 \t  0\n",
        "\t    1    3 \t  1\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 0.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    9 \t  3\n",
        "\t    1    0 \t  4\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    11 \t  1\n",
        "\t    1    1 \t  3\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 320 iterations: limit on f Precision\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    11 \t  1\n",
        "\t    1    2 \t  2\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    11 \t  1\n",
        "\t    1    2 \t  2\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    10 \t  2\n",
        "\t    1    0 \t  4\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 378 iterations: limit on f Precision\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    12 \t  0\n",
        "\t    1    2 \t  2\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "SCG stopped after"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 401 iterations: did not converge\n",
        "[[ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]]\n",
        "\t Confusion matrix\n",
        "\t    predicted labels\n",
        "\t \t 0 \t 1\n",
        "true lables 0    10 \t  2\n",
        "\t    1    2 \t  2\n",
        "74.5833333333\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "neuralnetworks.py:297: RuntimeWarning: invalid value encountered in divide\n",
        "  Y = np.hstack((expY / denom, 1/denom))\n",
        "neuralnetworks.py:298: RuntimeWarning: divide by zero encountered in log\n",
        "  return -np.mean(T * np.log(Y))\n",
        "neuralnetworks.py:298: RuntimeWarning: invalid value encountered in multiply\n",
        "  return -np.mean(T * np.log(Y))\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}