{
 "metadata": {
  "name": "Untitled0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "import numpy as np\n",
      "from scipy import linalg\n",
      "from scipy import sparse\n",
      "from matplotlib import pyplot as plt\n",
      "import random\n",
      "import sys\n",
      "import math\n",
      "\n",
      "\n",
      "def gtm_rctg(samp_size):\n",
      "    xDim = samp_size\n",
      "    yDim = samp_size\n",
      "    # Produce a grid with the right number of rows and columns\n",
      "    X, Y = np.meshgrid(np.linspace(0,(xDim-1),xDim), np.linspace(0,(yDim-1),yDim))\n",
      "    # Change grid representation \n",
      "    sample = np.zeros((xDim**2,2))\n",
      "    sample[:,0:1]=np.reshape(X,(xDim**2,1),1)\n",
      "    sample[:,1:2]=np.reshape(Y,(yDim**2,1),1)\n",
      "    # Shift grid to correct position and scale it\n",
      "    maxXY= np.max(sample,0);\n",
      "    sample[:,0:1] = 2*(sample[:,0:1] - maxXY[0]/2)/maxXY[0]\n",
      "    sample[:,1:2] = -2*(sample[:,1:2] - maxXY[1]/2)/maxXY[1]\n",
      "    return sample\n",
      "\n",
      "def dist(x,c):\n",
      "#Calculate squared euclidean distance between x and c\n",
      "    ndata = x.shape[0]\n",
      "    dimx = x.shape[1]\n",
      "    ncentres = c.shape[0]\n",
      "    dimc = c.shape[1]\n",
      "    x2 = np.reshape(sum(np.square(x).T),(1,ndata))\n",
      "    c2 = np.reshape(sum(np.square(c).T),(1,ncentres))\n",
      "    n2 = (np.dot(np.ones((ncentres, 1)) , x2)).T +np.dot(np.ones((ndata, 1)),c2) -  2*(np.dot(x,c.T))\n",
      "    # Rounding errors occasionally cause negative entries in n2\n",
      "    n2 = np.where(n2>=0,n2,0)\n",
      "    return n2\n",
      "\n",
      "def rbfsetfw(rbf_c,rbf_w,scale):   \n",
      "# Set the function widths of the RBF network\n",
      "    cdist = dist(rbf_c,rbf_c)\n",
      "    if scale > 0.0:\n",
      "    # Set variance of basis to be scale times average distance to nearest neighbour\n",
      "        cdist = cdist + sys.float_info.max*np.eye(rbf_c.shape[0])\n",
      "        widths = scale*np.mean((cdist).min(axis=0))\n",
      "    else:\n",
      "        widths = np.max(cdist)\n",
      "    wi = widths * np.ones(rbf_w.shape)\n",
      "    return wi\n",
      "\n",
      "def eigdec(x, N):\n",
      "    temp_evals, temp_evec = np.linalg.eig(x)\n",
      "    evals = np.sort(-temp_evals)\n",
      "    perm = np.argsort(-temp_evals)\n",
      "    evals = -evals[0:N]\n",
      "    evec = np.zeros((temp_evec.shape[0],N),dtype=complex)\n",
      "    if (evals[0:N] == temp_evals[0:N]).all():\n",
      "        evec = temp_evec[:,0:N]\n",
      "    else:\n",
      "        for i in range(N):\n",
      "            evec[:,i] = temp_evec[:,perm[i]] \n",
      "    return evals, evec   \n",
      "\n",
      "def rbffwd(c, x, wi, w2, b2):\n",
      "    nx = x.shape[0]\n",
      "    ndim = x.shape[1]\n",
      "    n2 = dist(x, c)\n",
      "    # Calculate width factors: net.wi contains squared widths\n",
      "    wi2 = np.ones((nx, 1)) * (2 * wi)\n",
      "    # Now compute the activations\n",
      "    z = np.exp(-(n2/wi2))\n",
      "    a = np.dot(z,w2) + np.dot(np.ones((nx, 1)),b2)\n",
      "    return a, z, n2\n",
      "\n",
      "def gmmactive(nin, covars, gmm_c, ncentres, data):\n",
      "    a = np.zeros((data.shape[0], ncentres))\n",
      "    # Calculate squared norm matrix, of dimension (ndata, ncentres)\n",
      "    n2 = dist(data, gmm_c)/10000\n",
      "    # Calculate width factors\n",
      "    wi2 = np.dot(np.ones((data.shape[0], 1)), (2 * covars))\n",
      "    #normal = (math.pi* wi2)**(nin/2)\n",
      "    # Now compute the activations\n",
      "    #a = np.exp(-(n2/wi2))/ normal\n",
      "    a = np.exp(-(n2/wi2))\n",
      "    return a\n",
      "    \n",
      "\n",
      "def gtmpost(nin, covars, gmm_c, ncentres, priors, rbf_c, X, wi, w2, b2, data):\n",
      "    gmm_centres = rbffwd(rbf_c, X, wi, w2, b2)\n",
      "    a = gmmactive(nin, covars, gmm_c, ncentres, data)\n",
      "    post = (np.dot(np.ones((data.shape[0], 1)),priors))*a\n",
      "    s = np.reshape(post.sum(axis=1).T,(data.shape[0],1))\n",
      "    # Set any zeros to one before dividing\n",
      "    s = np.where(s>0,s,1)\n",
      "    post = post/np.dot(s,np.ones((1, ncentres)))\n",
      "    return post, a\n",
      "\n",
      "#def drawSignal(classData, plotData, xmin, ymin, xmax, ymax, color):\n",
      "\n",
      "\n",
      "def _get_limits(ax):\n",
      "    \"\"\" Return X and Y limits for the passed axis as [[xlow,xhigh],[ylow,yhigh]]\n",
      "    \"\"\"\n",
      "    return [list(ax.get_xlim()), list(ax.get_ylim())]\n",
      "\n",
      "def _set_limits( ax, lims ):\n",
      "    \"\"\" Set X and Y limits for the passed axis\n",
      "    \"\"\"\n",
      "    ax.set_xlim(*(lims[0]))\n",
      "    ax.set_ylim(*(lims[1]))\n",
      "    return\n",
      "\n",
      "def pre_zoom( fig ):\n",
      "    \"\"\" Initialize history used by the re_zoom() event handler.\n",
      "        Call this after plots are configured and before plt.show().\n",
      "    \"\"\"\n",
      "    global oxy\n",
      "    oxy = [_get_limits(ax) for ax in fig.axes]\n",
      "    # :TODO: Intercept the toolbar Home, Back and Forward buttons.\n",
      "    return\n",
      "\n",
      "def re_zoom(event):\n",
      "    \"\"\" plt event handler to zoom all plots together, but permit them to\n",
      "        scroll independently.  Created to support eyeball correlation.\n",
      "        Use with 'motion_notify_event' and 'button_release_event'.\n",
      "    \"\"\"\n",
      "    global oxy\n",
      "    for ax in event.canvas.figure.axes:\n",
      "        navmode = ax.get_navigate_mode()\n",
      "        if navmode is not None:\n",
      "            break\n",
      "    scrolling = (event.button == 1) and (navmode == \"PAN\")\n",
      "    if scrolling:                   # Update history (independent of event type)\n",
      "        oxy = [_get_limits(ax) for ax in event.canvas.figure.axes]\n",
      "        return\n",
      "    if event.name != 'button_release_event':    # Nothing to do!\n",
      "        return\n",
      "    # We have a non-scroll 'button_release_event': Were we zooming?\n",
      "    zooming = (navmode == \"ZOOM\") or ((event.button == 3) and (navmode == \"PAN\"))\n",
      "    if not zooming:                 # Nothing to do!\n",
      "        oxy = [_get_limits(ax) for ax in event.canvas.figure.axes]  # To be safe\n",
      "        return\n",
      "    # We were zooming, but did anything change?  Check for zoom activity.\n",
      "    changed = None\n",
      "    print '66666333311115555 ',ax.get_xlim()\n",
      "    zoom = [[0.0,0.0],[0.0,0.0]]    # Zoom from each end of axis (2 values per axis)\n",
      "    '''for i, ax in enumerate(event.canvas.figure.axes): # Get the axes\n",
      "        # Find the plot that changed\n",
      "        nxy = _get_limits(ax)\n",
      "        if (oxy[i] != nxy):         # This plot has changed\n",
      "            changed = i\n",
      "            # Calculate zoom factors\n",
      "            for j in [0,1]:         # Iterate over x and y for each axis\n",
      "                # Indexing: nxy[x/y axis][lo/hi limit]\n",
      "                #           oxy[plot #][x/y axis][lo/hi limit]\n",
      "                width = oxy[i][j][1] - oxy[i][j][0]\n",
      "                # Determine new axis scale factors in a way that correctly\n",
      "                # handles simultaneous zoom + scroll: Zoom from each end.\n",
      "                zoom[j] = [(nxy[j][0] - oxy[i][j][0]) / width,  # lo-end zoom\n",
      "                           (oxy[i][j][1] - nxy[j][1]) / width]  # hi-end zoom\n",
      "            break '''                  # No need to look at other axes\n",
      "    '''if changed is not None:\n",
      "        for i, ax in enumerate(event.canvas.figure.axes): # change the scale\n",
      "            if i == changed:\n",
      "                continue\n",
      "            for j in [0,1]:\n",
      "                width = oxy[i][j][1] - oxy[i][j][0]\n",
      "                nxy[j] = [oxy[i][j][0] + (width*zoom[j][0]),\n",
      "                          oxy[i][j][1] - (width*zoom[j][1])]\n",
      "            _set_limits(ax, nxy)\n",
      "        event.canvas.draw()         # re-draw the canvas (if required)\n",
      "        pre_zoom(event.canvas.figure)   # Update history'''\n",
      "    return\n",
      "# End re_zoom()\n",
      "'''\n",
      "def zoom_factory(ax,base_scale = 2.):\n",
      "    def zoom_fun(event):\n",
      "        # get the current x and y limits\n",
      "        cur_xlim = ax.get_xlim()\n",
      "        cur_ylim = ax.get_ylim()\n",
      "        # set the range\n",
      "        cur_xrange = (cur_xlim[1] - cur_xlim[0])*.5\n",
      "        cur_yrange = (cur_ylim[1] - cur_ylim[0])*.5\n",
      "        xdata = event.xdata # get event x location\n",
      "        ydata = event.ydata # get event y location\n",
      "        if event.button == 'up':\n",
      "            # deal with zoom in\n",
      "            scale_factor = 1/base_scale\n",
      "        elif event.button == 'down':\n",
      "            # deal with zoom out\n",
      "            scale_factor = base_scale\n",
      "        else:\n",
      "            # deal with something that should never happen\n",
      "            scale_factor = 1\n",
      "            print event.button\n",
      "        # set new limits\n",
      "        ax.set_xlim([xdata - cur_xrange*scale_factor,\n",
      "                     xdata + cur_xrange*scale_factor])\n",
      "        ax.set_ylim([ydata - cur_yrange*scale_factor,\n",
      "                     ydata + cur_yrange*scale_factor])\n",
      "        ax.figure.canvas.draw() # force re-draw\n",
      " \n",
      "    fig = ax.get_figure() # get the figure of interest\n",
      "    # attach the call back\n",
      "    fig.canvas.mpl_connect('scroll_event',zoom_fun)\n",
      " \n",
      "    #return the function\n",
      "    return zoom_fun'''\n",
      "\n",
      "#*******************************************************************************************************************************************88\n",
      "    \t\n",
      "data=np.loadtxt('P4all3protS11.txt')\n",
      "print '###',data.shape\n",
      "data_features = data[:,2:212]\n",
      "data_classes = data[:,1:2]\n",
      "\n",
      "#data_dim = data_features.shape[1]  # Data dimension\n",
      "data_dim = 210\n",
      "print data_dim\n",
      "data_samples = data_features.shape[0]\n",
      "\n",
      "# Create the latent space\n",
      "\n",
      "latent_dim_points = 15  # Number of latent points in each dimension\n",
      "nlatent = latent_dim_points**2  # Number of latent points\n",
      "latent_dim = 2  # Dimension of the latent space\n",
      "\n",
      "\n",
      "#plt.plot(data_features[0,:],)\n",
      "#plt.show()\n",
      "\n",
      "########## Create the GTM \n",
      "\n",
      "gtm_nin = data_dim     # Number of input units to the GTM\n",
      "gtm_dimLatent = latent_dim   #Latent dimension of the GTM\n",
      "gtm_X = []      # Sample latent points in the GTM\n",
      "\n",
      "########### Create the RBF space\n",
      "\n",
      "rbf_dim_points = 4\n",
      "rbf_width_factor = 1\n",
      "num_rbf_centres = rbf_dim_points**2\n",
      "rbf_nhidden = num_rbf_centres  # Number of hidden units\n",
      "rbf_nin = latent_dim     # Number of input units\n",
      "rbf_nout = data_dim    # Number of output units\n",
      "rbf_nwts = (rbf_nin+1)*rbf_nhidden + (rbf_nhidden+1)*rbf_nout   # Number of total weights and biases\n",
      "rbf_actfn = 'gaussian'  # For radially symmetric gaussian functions as the activation function, the implementation is based on gaussian\n",
      "rbf_outfn = 'linear'    # Defines the output error function, linear for linear outputs and SoS error\n",
      "# Separate the weights into its components, initialized to random normal values\n",
      "w = np.random.randn(1,rbf_nwts)\n",
      "mark1 = rbf_nin*rbf_nhidden\n",
      "mark2 = mark1 + rbf_nhidden\n",
      "mark3 = mark2 + rbf_nhidden*rbf_nout\n",
      "mark4 = mark3 + rbf_nout\n",
      "rbf_centres = np.reshape(w[:,0:mark1],(rbf_nhidden,rbf_nin))   # RBF centres   \n",
      "rbf_wi = np.reshape(w[:,mark1:mark2],(1,rbf_nhidden))   # Squared widths needed for 'gaussian' type activation function\n",
      "rbf_w2 = np.reshape(w[:,mark2:mark3],(rbf_nhidden,rbf_nout))  # 2nd layer weight matrix \n",
      "rbf_b2 = np.reshape(w[:,mark3:mark4],(1,rbf_nout))   # 2nd layer bias vector\n",
      "#Make widths equal to one\n",
      "rbf_wi = np.ones((1,rbf_nhidden))\n",
      "'''\n",
      "print 'rbf_centres',rbf_centres\n",
      "print 'rbf_wi',rbf_wi\n",
      "print 'rbf_w2',rbf_w2\n",
      "print 'rbf_b2',rbf_b2'''\n",
      "\n",
      "########## Create the Gaussian Mixture model\n",
      "\n",
      "gmm_nin = data_dim\n",
      "gmm_ncentres = nlatent\n",
      "gmm_covartype = 'spherical'  # Allows single variance parameter for each component(stored as a vector)\n",
      "gmm_priors = np.ones((1,gmm_ncentres))/gmm_ncentres    #Priors are the mixing coefficients. Initialized to equal values summing to one, and the covariance are all the identity matrices\n",
      "gmm_centres = np.random.randn(gmm_ncentres,gmm_nin)   # Initialized from tandom normal distribution\n",
      "gmm_covars = np.ones((1,gmm_ncentres))\n",
      "gmm_nwts = gmm_ncentres + gmm_ncentres*gmm_nin + gmm_ncentres    # Total number of weights and biases\n",
      "'''\n",
      "print('gmm priors',gmm_priors)\n",
      "print(gmm_priors.shape)\n",
      "print('gmm centres',gmm_centres)\n",
      "print('gmm nwts',gmm_nwts)'''\n",
      "\n",
      "######## Initialize the weights and latent samples in the GTM. Generates a sample of latent data points and sets the centres and widths of the RBF network\n",
      "\n",
      "gtm_X = gtm_rctg(latent_dim_points)\n",
      "rbf_centres = gtm_rctg(rbf_dim_points)\n",
      "rbf_wi = rbfsetfw(rbf_centres, rbf_wi, rbf_width_factor)\n",
      "# Calculate the principal components\n",
      "PCcoeff, PCvec = eigdec(np.cov(data_features.T), data_features.shape[1])\n",
      "PCcoeff = np.reshape(PCcoeff,(1,PCcoeff.shape[0]))\n",
      "A = PCvec[:, 0:gtm_dimLatent]*np.diag(np.sqrt(PCcoeff[0:gtm_dimLatent]))\n",
      "# Forward prpagate through the RBF network\n",
      "a , Phi, dist1 = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "# Normalise X to ensure 1:1 mapping of variances and calculate weights as solution of Phi*W = normX*A'\n",
      "normX = np.dot((gtm_X - np.dot(np.ones(gtm_X.shape),np.diag(np.mean(gtm_X,0)))),np.diag(1/np.std(gtm_X,0)))\n",
      "g = np.dot(normX,A.T)\n",
      "x_sol, residues, rank, singV = linalg.lstsq(Phi,g)            \n",
      "rbf_w2 = np.asarray(x_sol)\n",
      "# Bias is mean of target data\n",
      "rbf_b2 = np.reshape(np.mean(data_features,axis=0),(data_dim,1)).T\n",
      "# Must also set initial value of variance. Find average distance between nearest centres. Ensure that distance of centre to itself is excluded by setting diagonal entries to realmax\n",
      "print 'rbf_b2',rbf_b2.shape\n",
      "gmm_centres, not_used1, not_used2 = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "print  'gmm_centres',gmm_centres\n",
      "d = dist(gmm_centres, gmm_centres) + np.matrix(np.identity(gmm_ncentres))*sys.float_info.max\n",
      "print dist(gmm_centres, gmm_centres)\n",
      "print np.mean(dist(gmm_centres, gmm_centres).min(axis=0))/2\n",
      "print np.mean(d.min(axis=0))/2\n",
      "print '%%%%%',np.matrix(np.identity(gmm_ncentres))*sys.float_info.max\n",
      "print 'd',d\n",
      "sigma = np.mean(d.min(axis=0))/2\n",
      "print 'Sigma1',sigma\n",
      "# Now set covariance to minimum of this and next largest eigenvalue\n",
      "if gtm_dimLatent < data.shape[1]:\n",
      "  sigma = min(sigma, PCcoeff[:,gtm_dimLatent:gtm_dimLatent+1]);\n",
      "\n",
      "print 'Sigma*****', sigma\n",
      "gmm_covars = sigma*np.ones((1, gmm_ncentres))\n",
      "\n",
      "\n",
      "\n",
      "############ Training the model with EM algorithm #########################################\n",
      "\n",
      "niters = 30\n",
      "ND = data_dim * data_samples \n",
      "gmm_centres, Phi, l = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "Phi = np.hstack((Phi, np.ones((gtm_X.shape[0], 1))))\n",
      "PhiT = Phi.T\n",
      "K, Mplus1 = Phi.shape\n",
      "\n",
      "\n",
      "print 'gmm_covars',gmm_covars,'\\n'\n",
      "print 'gmm_centres',gmm_centres,'\\n'\n",
      "print 'gmm_priors',gmm_priors,'\\n'\n",
      "print 'rbf_centres',rbf_centres,'\\n'\n",
      "print 'gtm_X',gtm_X,'\\n'\n",
      "print 'rbf_wi',rbf_wi,'\\n'\n",
      "print 'rbf_w2',rbf_w2,'\\n'\n",
      "print 'rbf_b2',rbf_b2,'\\n'\n",
      "print 'data_features',data_features,'\\n'\n",
      "\n",
      "\n",
      "for n in range(niters):\n",
      "\n",
      "    # Calculate responsibilities\n",
      "    R, act = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, data_features)\n",
      "    # Calculate matrix be inverted (Phi'*G*Phi + alpha*I in the papers).\n",
      "    # Sparse representation of G normally executes faster and saves memory\n",
      "    A = np.dot(PhiT,np.dot(sparse.spdiags(np.sum(R,axis=0).T, 0, K, K).todense(),Phi))\n",
      "    W = np.linalg.solve(A,np.dot(PhiT,np.dot(R.T,data_features)))\n",
      "    rbf_w2 = W[0:rbf_nhidden, :]\n",
      "    print rbf_w2.shape\n",
      "    rbf_b2 = W[rbf_nhidden:rbf_nhidden+1, :]\n",
      "    print rbf_b2.shape\n",
      "    d = dist(data_features, np.dot(Phi,W))\n",
      "   \n",
      "    # Calculate new value for beta\n",
      "    gmm_covars = np.dot(np.ones((1, gmm_ncentres)),(sum(sum(d*R))/ND))\n",
      "    print gmm_covars.shape\n",
      "\n",
      "\n",
      "\n",
      "forMM, notused = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, data_features)\n",
      "\n",
      "\n",
      "means = np.dot(forMM, gtm_X)\n",
      "print gtm_X.shape\n",
      "print '$$',means.shape\n",
      "# Mode is maximum responsibility\n",
      "max_index = np.argmax(forMM, axis=1)\n",
      "modes = gtm_X[max_index, :]\n",
      "classesBN = np.where(data_classes==0)[0]\n",
      "classesPN = np.where(data_classes== -1)[0]\n",
      "classesDN = np.where(data_classes== -2)[0]\n",
      "\n",
      "fig = plt.figure(figsize=(9,9))\n",
      "\n",
      "pre_zoom(fig)\n",
      "axes1 = fig.add_axes([0.1, 0.1, 0.8,0.8]) # main axes\n",
      "\n",
      "xmin, xmax = axes1.get_xlim()\n",
      "print '%$%$%$%$%$%$%$%$%$%$%$%', xmin,'    ',xmax\n",
      "\n",
      "\n",
      "for i in classesBN:\n",
      "    #print means[i,0],\" , \", means[i,1]\n",
      "    axes2 = fig.add_axes([(means[i,0]-(-0.003))/0.009*0.8+0.1-0.01, (means[i,1]-(-0.004))/0.009*0.8+0.1-0.01, 0.05,0.05])\n",
      "    axes2.set_alpha(0.0)\n",
      "    axes1.plot(means[i,0], means[i,1], 'k.')\n",
      "    bn = axes2.plot(data_features[i,:],'r')\n",
      "    axes2.legend()\n",
      "    axes2.axis('off')\n",
      "\n",
      "for i in classesPN:\n",
      "    #print means[i,0],\" , \", means[i,1]\n",
      "    axes2 = fig.add_axes([(means[i,0]-(-0.003))/0.009*0.8+0.1-0.01, (means[i,1]-(-0.004))/0.009*0.8+0.1-0.01, 0.05,0.05])\n",
      "    axes2.set_alpha(0.0)\n",
      "    axes1.plot(means[i,0], means[i,1], 'k.')\n",
      "    pn = axes2.plot(data_features[i,:],'y')\n",
      "    axes2.axis('off')\n",
      "\n",
      "for i in classesDN:\n",
      "    #print means[i,0],\" , \", means[i,1]\n",
      "    axes2 = fig.add_axes([(means[i,0]-(-0.003))/0.009*0.8+0.1-0.01, (means[i,1]-(-0.004))/0.009*0.8+0.1-0.01, 0.05,0.05])\n",
      "    axes2.set_alpha(0.0)\n",
      "    axes1.plot(means[i,0], means[i,1], 'k.')\n",
      "    dn = axes2.plot(data_features[i,:],'c')\n",
      "    axes2.axis('off')\n",
      "    #plt.plot(means[i,0], means[i,1], 'ro')\n",
      "classesB = np.where(data_classes==1)[0]\n",
      "classesP = np.where(data_classes==2)[0]\n",
      "classesD = np.where(data_classes==3)[0]\n",
      "\n",
      "for i in classesB:\n",
      "    axes2 = fig.add_axes([(means[i,0]-(-0.003))/0.009*0.8+0.1-0.01, (means[i,1]-(-0.004))/0.009*0.8+0.1-0.01, 0.05,0.05])\n",
      "    axes2.set_alpha(0.0)\n",
      "    axes1.plot(means[i,0], means[i,1],'kx')\n",
      "    b = axes2.plot(data_features[i,:],'b')\n",
      "    axes2.axis('off')\n",
      "\n",
      "for i in classesP:\n",
      "    axes2 = fig.add_axes([(means[i,0]-(-0.003))/0.009*0.8+0.1-0.01, (means[i,1]-(-0.004))/0.009*0.8+0.1-0.01, 0.05,0.05])\n",
      "    axes2.set_alpha(0.0)\n",
      "    axes1.plot(means[i,0], means[i,1],'kx')\n",
      "    p = axes2.plot(data_features[i,:],'g')\n",
      "    axes2.axis('off')\n",
      "\n",
      "for i in classesD:\n",
      "    axes2 = fig.add_axes([(means[i,0]-(-0.003))/0.009*0.8+0.1-0.01, (means[i,1]-(-0.004))/0.009*0.8+0.1-0.01, 0.05,0.05])\n",
      "    axes2.set_alpha(0.0)\n",
      "    axes1.plot(means[i,0], means[i,1],'kx')\n",
      "    d = axes2.plot(data_features[i,:],'m')\n",
      "    axes2.axis('off')\n",
      "#axes1.set_xlabel('x')\n",
      "#axes1.set_ylabel('y')\n",
      "#axes1.set_title('title')\n",
      "\n",
      "#plt.legend(loc='upper center', shadow=True)\n",
      "\n",
      "\n",
      "#plt.connect('motion_notify_event', re_zoom)  # for right-click pan/zoom\n",
      "plt.connect('button_release_event',re_zoom)  # for rectangle-select zoom\n",
      "#fig.show()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-2-041ef71b589b>, line 101)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-041ef71b589b>\"\u001b[1;36m, line \u001b[1;32m101\u001b[0m\n\u001b[1;33m    def _get_limits(ax):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}