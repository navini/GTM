{
 "metadata": {
  "name": "",
  "signature": "sha256:e8d357887c9034810daf5d33cc6797c0d4af522931ec608db821a2c72b46a6c8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from scipy import linalg\n",
      "from scipy import sparse\n",
      "from matplotlib import pyplot as plt\n",
      "import random\n",
      "import sys\n",
      "import math\n",
      "import neuralnetworks as nn\n",
      "import mlutils as ml\n",
      "import random\n",
      "from __future__ import division\n",
      "\n",
      "def normalize(signal):\n",
      "    means = np.mean(signal, axis=1).reshape((signal.shape[0],1))\n",
      "    std = np.std(signal, axis=1).reshape((signal.shape[0],1))\n",
      "    signal = np.divide(np.subtract(signal,means),std)\n",
      "    return signal\n",
      "    \n",
      "\n",
      "def gtm_rctg(samp_size):\n",
      "    xDim = samp_size\n",
      "    yDim = samp_size\n",
      "    # Produce a grid with the right number of rows and columns\n",
      "    X, Y = np.meshgrid(np.linspace(0,(xDim-1),xDim), np.linspace(0,(yDim-1),yDim))\n",
      "    # Change grid representation \n",
      "    sample = np.zeros((xDim**2,2))\n",
      "    sample[:,0:1]=np.reshape(X,(xDim**2,1),1)\n",
      "    sample[:,1:2]=np.reshape(Y,(yDim**2,1),1)\n",
      "    # Shift grid to correct position and scale it\n",
      "    maxXY= np.max(sample,0);\n",
      "    sample[:,0:1] = 2*(sample[:,0:1] - maxXY[0]/2)/maxXY[0]\n",
      "    sample[:,1:2] = -2*(sample[:,1:2] - maxXY[1]/2)/maxXY[1]\n",
      "    return sample\n",
      "\n",
      "def dist(x,c):\n",
      "#Calculate squared euclidean distance between x and c\n",
      "    ndata = x.shape[0]\n",
      "    dimx = x.shape[1]\n",
      "    ncentres = c.shape[0]\n",
      "    dimc = c.shape[1]\n",
      "    x2 = np.reshape(sum(np.square(x).T),(1,ndata))\n",
      "    c2 = np.reshape(sum(np.square(c).T),(1,ncentres))\n",
      "    n2 = (np.dot(np.ones((ncentres, 1)) , x2)).T +np.dot(np.ones((ndata, 1)),c2) -  2*(np.dot(x,c.T))\n",
      "    # Rounding errors occasionally cause negative entries in n2\n",
      "    n2 = np.where(n2>=0,n2,0)\n",
      "    return n2\n",
      "\n",
      "def rbfsetfw(rbf_c,rbf_w,scale):   \n",
      "# Set the function widths of the RBF network\n",
      "    cdist = dist(rbf_c,rbf_c)\n",
      "    if scale > 0.0:\n",
      "    # Set variance of basis to be scale times average distance to nearest neighbour\n",
      "        cdist = cdist + sys.float_info.max*np.eye(rbf_c.shape[0])\n",
      "        widths = scale*np.mean((cdist).min(axis=0))\n",
      "    else:\n",
      "        widths = np.max(cdist)\n",
      "    wi = widths * np.ones(rbf_w.shape)\n",
      "    return wi\n",
      "\n",
      "def eigdec(x, N):\n",
      "    temp_evals, temp_evec = np.linalg.eig(x)\n",
      "    #temp_evals = np.sort(temp_evals)\n",
      "    evals = np.sort(-temp_evals)\n",
      "    perm = np.argsort(-temp_evals)\n",
      "    evals = -evals[0:N]\n",
      "    evec = np.zeros((temp_evec.shape[0],N), dtype=complex)\n",
      "    if (evals[0:N] == temp_evals[0:N]).all():\n",
      "        evec = temp_evec[:,0:N]\n",
      "    else:\n",
      "        for i in range(N):\n",
      "            evec[:,i] = temp_evec[:,perm[i]] \n",
      "    return evals, evec   \n",
      "\n",
      "def rbffwd(c, x, wi, w2, b2):\n",
      "    nx = x.shape[0]\n",
      "    ndim = x.shape[1]\n",
      "    n2 = dist(x, c)\n",
      "    # Calculate width factors: net.wi contains squared widths\n",
      "    wi2 = np.ones((nx, 1)) * (2 * wi)\n",
      "    # Now compute the activations\n",
      "    z = np.exp(-(n2/wi2))\n",
      "    a = np.dot(z,w2) + np.dot(np.ones((nx, 1)),b2)\n",
      "    return a, z, n2\n",
      "\n",
      "def gmmactive(nin, covars, gmm_c, ncentres, data):\n",
      "    a = np.zeros((data.shape[0], ncentres))\n",
      "    # Calculate squared norm matrix, of dimension (ndata, ncentres)\n",
      "    n2 = dist(data, gmm_c)\n",
      "    # Calculate width factors\n",
      "    wi2 = np.dot(np.ones((data.shape[0], 1)), (2 * covars))\n",
      "    #normal = (math.pi* wi2)**(nin/2)\n",
      "    # Now compute the activations\n",
      "    #a = np.exp(-(n2/wi2))/ normal\n",
      "    a = np.exp(-(n2/wi2))\n",
      "    return a\n",
      "    \n",
      "\n",
      "def gtmpost(nin, covars, gmm_c, ncentres, priors, rbf_c, X, wi, w2, b2, data):\n",
      "    gmm_centres = rbffwd(rbf_c, X, wi, w2, b2)\n",
      "    a = gmmactive(nin, covars, gmm_c, ncentres, data)\n",
      "    post = (np.dot(np.ones((data.shape[0], 1)),priors))*a\n",
      "    s = np.reshape(post.sum(axis=1).T,(data.shape[0],1))\n",
      "    # Set any zeros to one before dividing\n",
      "    s = np.where(s>0,s,1)\n",
      "    post = post/np.dot(s,np.ones((1, ncentres)))\n",
      "    return post, a\n",
      "\n",
      "def experiment(hs,nIter,X,T,Xtest,Ytest):\n",
      "    nnet = nn.NeuralNetwork(2,hs,2)\n",
      "    print T\n",
      "    nnet.train(X,T,weightPrecision=1.e-8,errorPrecision=1.e-8,nIterations=nIter)\n",
      "    (Y,Z) = nnet.use(X, allOutputs=True)\n",
      "    print Y\n",
      "    Ytest = nnet.use(Xtest,allOutputs=True)\n",
      "    return Ytest\n",
      "\n",
      "#*******************************************************************************************************************************************88\n",
      "    \t\n",
      "    \n",
      "data=np.loadtxt('classData4smoothed.txt')\n",
      "data_features1 = data[:,1:211]\n",
      "data_classes1 = data[:,0:1]\n",
      "###########Print Confusion Matrix\n",
      "\n",
      "print data_features1.shape\n",
      "BSR = np.zeros((10,1))\n",
      "hiddens = [[1], [1,1], [1,1,1], [1,2,1]]\n",
      "\n",
      "for k in range(10):\n",
      "    for hs in hiddens:\n",
      "        TP=0\n",
      "        TN=0\n",
      "        FP=0\n",
      "        FN=0\n",
      "\n",
      "        for i in range(data_features1.shape[0]):\n",
      "            print '##',i\n",
      "            test_data = data_features1[i:i+1,:]\n",
      "            test_classes = data_classes1[i:i+1,:]\n",
      "            data_featurestrain = np.delete(data_features1, (i), axis=0 )\n",
      "            train_classes = np.delete(data_classes1, (i), axis=0 )\n",
      "\n",
      "\n",
      "            #data_dim = data_features.shape[1]  # Data dimension\n",
      "            data_dim = 210\n",
      "            data_samples = data_featurestrain.shape[0]\n",
      "\n",
      "            data_features = normalize(data_featurestrain)\n",
      "            test_data = normalize(test_data)\n",
      "            data_classes = train_classes\n",
      "\n",
      "\n",
      "            # Create the latent space\n",
      "\n",
      "            latent_dim_points = 15  # Number of latent points in each dimension\n",
      "            nlatent = latent_dim_points**2  # Number of latent points\n",
      "            latent_dim = 2  # Dimension of the latent space\n",
      "\n",
      "\n",
      "            #plt.plot(data_features[0,:],)\n",
      "            #plt.show()\n",
      "\n",
      "            ########## Create the GTM \n",
      "\n",
      "            gtm_nin = data_dim     # Number of input units to the GTM\n",
      "            gtm_dimLatent = latent_dim   #Latent dimension of the GTM\n",
      "            gtm_X = []      # Sample latent points in the GTM\n",
      "\n",
      "            ########### Create the RBF space\n",
      "\n",
      "            rbf_dim_points = 4\n",
      "            rbf_width_factor = 1\n",
      "            num_rbf_centres = rbf_dim_points**2\n",
      "            rbf_nhidden = num_rbf_centres  # Number of hidden units\n",
      "            rbf_nin = latent_dim     # Number of input units\n",
      "            rbf_nout = data_dim    # Number of output units\n",
      "            rbf_nwts = (rbf_nin+1)*rbf_nhidden + (rbf_nhidden+1)*rbf_nout   # Number of total weights and biases\n",
      "            rbf_actfn = 'gaussian'  # For radially symmetric gaussian functions as the activation function, the implementation is based on gaussian\n",
      "            rbf_outfn = 'linear'    # Defines the output error function, linear for linear outputs and SoS error\n",
      "            # Separate the weights into its components, initialized to random normal values\n",
      "            w = np.random.randn(1,rbf_nwts)\n",
      "            mark1 = rbf_nin*rbf_nhidden\n",
      "            mark2 = mark1 + rbf_nhidden\n",
      "            mark3 = mark2 + rbf_nhidden*rbf_nout\n",
      "            mark4 = mark3 + rbf_nout\n",
      "            rbf_centres = np.reshape(w[:,0:mark1],(rbf_nhidden,rbf_nin))   # RBF centres   \n",
      "            rbf_wi = np.reshape(w[:,mark1:mark2],(1,rbf_nhidden))   # Squared widths needed for 'gaussian' type activation function\n",
      "            rbf_w2 = np.reshape(w[:,mark2:mark3],(rbf_nhidden,rbf_nout))  # 2nd layer weight matrix \n",
      "            rbf_b2 = np.reshape(w[:,mark3:mark4],(1,rbf_nout))   # 2nd layer bias vector\n",
      "            #Make widths equal to one\n",
      "            rbf_wi = np.ones((1,rbf_nhidden))\n",
      "\n",
      "            ########## Create the Gaussian Mixture model\n",
      "\n",
      "            gmm_nin = data_dim\n",
      "            gmm_ncentres = nlatent\n",
      "            gmm_covartype = 'spherical'  # Allows single variance parameter for each component(stored as a vector)\n",
      "            gmm_priors = np.ones((1,gmm_ncentres))/gmm_ncentres    #Priors are the mixing coefficients. Initialized to equal values summing to one, and the covariance are all the identity matrices\n",
      "            gmm_centres = np.random.randn(gmm_ncentres,gmm_nin)   # Initialized from tandom normal distribution\n",
      "            gmm_covars = np.ones((1,gmm_ncentres))\n",
      "            gmm_nwts = gmm_ncentres + gmm_ncentres*gmm_nin + gmm_ncentres    # Total number of weights and biases\n",
      "\n",
      "\n",
      "            ######## Initialize the weights and latent samples in the GTM. Generates a sample of latent data points and sets the centres and widths of the RBF network\n",
      "\n",
      "            gtm_X = gtm_rctg(latent_dim_points)\n",
      "            rbf_centres = gtm_rctg(rbf_dim_points)\n",
      "            rbf_wi = rbfsetfw(rbf_centres, rbf_wi, rbf_width_factor)\n",
      "            # Calculate the principal components\n",
      "\n",
      "            PCcoeff, PCvec = eigdec(np.cov(data_features.T), data_features.shape[1])\n",
      "            PCcoeff = np.reshape(PCcoeff,(1,PCcoeff.shape[0]))\n",
      "\n",
      "            A = np.dot(PCvec[:, 0:gtm_dimLatent],np.diag(np.asarray(np.sqrt(PCcoeff[:,0:gtm_dimLatent])).reshape(-1)))\n",
      "\n",
      "            # Forward prpagate through the RBF network\n",
      "            a , Phi, dist1 = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "            # Normalise X to ensure 1:1 mapping of variances and calculate weights as solution of Phi*W = normX*A'\n",
      "            normX = np.dot((gtm_X - np.dot(np.ones(gtm_X.shape),np.diag(np.mean(gtm_X,0)))),np.diag(1/np.std(gtm_X,0)))\n",
      "            g = np.dot(normX,A.T)\n",
      "            x_sol, residues, rank, singV = linalg.lstsq(Phi,g)            \n",
      "            rbf_w2 = np.asarray(x_sol)\n",
      "            # Bias is mean of target data\n",
      "            rbf_b2 = np.reshape(np.mean(data_features,axis=0),(data_dim,1)).T\n",
      "            # Must also set initial value of variance. Find average distance between nearest centres. Ensure that distance of centre to itself is excluded by setting diagonal entries to realmax\n",
      "            gmm_centres, not_used1, not_used2 = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "            #print  'gmm_centres',gmm_centres\n",
      "            d = dist(gmm_centres, gmm_centres) + np.matrix(np.identity(gmm_ncentres))*sys.float_info.max\n",
      "\n",
      "            sigma = np.mean(d.min(axis=0))/2\n",
      "            # Now set covariance to minimum of this and next largest eigenvalue\n",
      "            if gtm_dimLatent < data.shape[1]:\n",
      "              sigma = min(sigma, PCcoeff[:,gtm_dimLatent:gtm_dimLatent+1]);\n",
      "\n",
      "            gmm_covars = sigma*np.ones((1, gmm_ncentres))\n",
      "\n",
      "\n",
      "\n",
      "            ############ Training the model with EM algorithm #########################################\n",
      "\n",
      "            niters = 30\n",
      "            ND = data_dim * data_samples \n",
      "            gmm_centres, Phi, l = rbffwd(rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2)\n",
      "            Phi = np.hstack((Phi, np.ones((gtm_X.shape[0], 1))))\n",
      "            PhiT = Phi.T\n",
      "            K, Mplus1 = Phi.shape\n",
      "\n",
      "\n",
      "            for n in range(niters):\n",
      "\n",
      "                # Calculate responsibilities\n",
      "                R, act = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, data_features)\n",
      "                # Calculate matrix be inverted (Phi'*G*Phi + alpha*I in the papers).\n",
      "                # Sparse representation of G normally executes faster and saves memory\n",
      "                A = np.dot(PhiT,np.dot(sparse.spdiags(np.sum(R,axis=0).T, 0, K, K).todense(),Phi))\n",
      "                W = np.linalg.solve(A,np.dot(PhiT,np.dot(R.T,data_features)))\n",
      "                rbf_w2 = W[0:rbf_nhidden, :]\n",
      "                #print rbf_w2.shape\n",
      "                rbf_b2 = W[rbf_nhidden:rbf_nhidden+1, :]\n",
      "                #print rbf_b2.shape\n",
      "                d = dist(data_features, np.dot(Phi,W))\n",
      "\n",
      "                # Calculate new value for beta\n",
      "                gmm_covars = np.dot(np.ones((1, gmm_ncentres)),(sum(sum(d*R))/ND))\n",
      "                #print gmm_covars.shape\n",
      "\n",
      "\n",
      "\n",
      "            forMM, notused = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, data_features)\n",
      "\n",
      "            means = np.dot(forMM, gtm_X)\n",
      "\n",
      "\n",
      "            targetcount = 0\n",
      "            nontargetcount = 0\n",
      "            if(test_classes==0):\n",
      "                targetPoints = np.zeros((20,3))\n",
      "                nontargetPoints = np.zeros((59,3))\n",
      "            else:\n",
      "                targetPoints = np.zeros((19,3))\n",
      "                nontargetPoints = np.zeros((60,3))\n",
      "            for i in range(data_classes.shape[0]):\n",
      "                if data_classes[i,0]==0:\n",
      "                    #lo=axes1.plot(means[i,0], means[i,1], 'r.')\n",
      "                    nontargetPoints[nontargetcount,0]=means[i,0]\n",
      "                    nontargetPoints[nontargetcount,1]=means[i,1]\n",
      "                    nontargetPoints[nontargetcount,2]=0\n",
      "                    nontargetcount=nontargetcount+1;\n",
      "                if data_classes[i,0]==1:\n",
      "                    #lx=axes1.plot(means[i,0], means[i,1], 'bx')\n",
      "                    targetPoints[targetcount,0]=means[i,0]\n",
      "                    targetPoints[targetcount,1]=means[i,1]\n",
      "                    targetPoints[targetcount,2]=1\n",
      "                    targetcount=targetcount+1;\n",
      "\n",
      "            X= np.vstack((nontargetPoints,targetPoints))\n",
      "            #axes1.set_title('Latent space')\n",
      "            #fig.show()\n",
      "            #plt.show()\n",
      "\n",
      "            forMM, notused = gtmpost(gmm_nin, gmm_covars, gmm_centres, gmm_ncentres, gmm_priors, rbf_centres, gtm_X, rbf_wi, rbf_w2, rbf_b2, test_data)\n",
      "            means = np.dot(forMM, gtm_X)\n",
      "\n",
      "\n",
      "            '''nnet = nn.NeuralNetClassifier(2,j+1,2) # 2 inputs, 8 hiddens, 3 outputs\n",
      "            nnet.train(X[:,0:2],X[:,2:3],weightPrecision=1.e-8,errorPrecision=1.e-8,nIterations=400)\n",
      "            print \"SCG stopped after\",nnet.getNumberOfIterations(),\"iterations:\",nnet.reason\n",
      "            (classes,Y,Z) = nnet.use(X[:,0:2], allOutputs=True)'''\n",
      "\n",
      "\n",
      "            marker = ['r.','bx']\n",
      "            predTest = np.zeros((1,1))\n",
      "            #predTest,probs,Z = nnet.use(means,allOutputs=True) \n",
      "            predTest = experiment(hs,400,X[:,0:2],X[:,2:3],means,predTest)\n",
      "            print ')))',predTest\n",
      "\n",
      "\n",
      "            if(predTest[0,:]==test_classes[0,:]):\n",
      "                if(predTest[0,:]==0):\n",
      "                    TN=TN+1\n",
      "                else:\n",
      "                    TP=TP+1\n",
      "            else:\n",
      "                if(predTest[0,:]==0):\n",
      "                    FN=FN+1\n",
      "                else:\n",
      "                    FP=FP+1\n",
      "\n",
      "\n",
      "        print '\\t Confusion matrix'\n",
      "\n",
      "        print '\\t    predicted labels'\n",
      "        print '\\t \\t 0 \\t 1'\n",
      "\n",
      "        print 'true lables 0   ',TN,'\\t ',FP\n",
      "        print '\\t    1   ',FN,'\\t ',TP\n",
      "\n",
      "        BSR[j,0] = BSR[j,0]+((TP/(TP+FN) + TN/(TN+FP))/2)\n",
      "        print BSR\n",
      "        \n",
      "BSR = BSR*10\n",
      "print BSR\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(80L, 210L)\n",
        "## 0\n",
        "[[ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 0.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]\n",
        " [ 1.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08182507  0.08181786]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175113  0.08174392]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.93190766  0.93190197]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.32695226  0.32694549]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08213861  0.0821314 ]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.09533409  0.09532691]\n",
        " [ 0.08175079  0.08174358]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08179737  0.08179016]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175143  0.08174422]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.33892925  0.3389225 ]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175191  0.0817447 ]\n",
        " [ 0.08175091  0.0817437 ]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175113  0.08174392]\n",
        " [ 0.08175085  0.08174364]\n",
        " [ 0.08175078  0.08174357]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08180189  0.08179468]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08180317  0.08179596]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.93190807  0.93190238]\n",
        " [ 0.93190805  0.93190236]\n",
        " [ 0.08175077  0.08174356]\n",
        " [ 0.93190807  0.93190238]\n",
        " [ 0.93190807  0.93190238]\n",
        " [ 0.08175291  0.0817457 ]\n",
        " [ 0.93190804  0.93190235]\n",
        " [ 0.93190803  0.93190235]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.9182009   0.91819519]\n",
        " [ 0.08175074  0.08174353]\n",
        " [ 0.92814057  0.92813488]\n",
        " [ 0.88881496  0.8888092 ]\n",
        " [ 0.9317886   0.93178291]\n",
        " [ 0.93190795  0.93190226]\n",
        " [ 0.2879812   0.28797436]\n",
        " [ 0.93190807  0.93190238]\n",
        " [ 0.91080781  0.91080209]\n",
        " [ 0.0817555   0.08174829]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "))) (array([[ 0.93190807+0.j,  0.93190238+0.j]]), [array([[-1.+0.j]])])\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "tuple indices must be integers, not tuple",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-452ec3abb99d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredTest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mtest_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredTest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                     \u001b[0mTN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTN\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers, not tuple"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}